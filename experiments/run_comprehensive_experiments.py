#!/usr/bin/env python3
"""
ç»¼åˆå®éªŒè¿è¡Œå™¨ - ä¾æ¬¡è¿è¡Œæ‰€æœ‰å®éªŒ
è¿è¡Œå®éªŒ1-6çš„çœŸå®å®éªŒè„šæœ¬å¹¶ç”Ÿæˆç»¼åˆæŠ¥å‘Š
"""

import numpy as np
import json
import matplotlib.pyplot as plt
from pathlib import Path
import subprocess
import time
import logging
from typing import Dict, List, Tuple
import os
import sys

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ComprehensiveExperimentRunner:
    """ç»¼åˆå®éªŒè¿è¡Œå™¨"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root).resolve()
        self.experiments_dir = self.project_root / "experiments"
        
        # å®éªŒé…ç½®
        self.experiments = {
            'exp_1_structure': {
                'name': 'ç»“æ„è¡¨å¾å®éªŒ',
                'script': 'exp_1_structure/run_structure_experiment.py',
                'description': 'éªŒè¯qHP Câ‚†â‚€ç½‘ç»œçš„ç»“æ„å‚æ•°å’Œåº”å˜å“åº”'
            },
            'exp_2_doping': {
                'name': 'æºæ‚åˆæˆå®éªŒ',
                'script': 'exp_2_doping/run_doping_experiment.py',
                'description': 'éªŒè¯qHP Câ‚†â‚€ç½‘ç»œçš„æºæ‚åˆæˆå’ŒåŒ–å­¦çŠ¶æ€'
            },
            'exp_3_electronic': {
                'name': 'ç”µå­æ€§è´¨æµ‹é‡å®éªŒ',
                'script': 'exp_3_electronic/run_electronic_experiment.py',
                'description': 'éªŒè¯ç”µå­æ€§è´¨å’ŒååŒæ•ˆåº”'
            },
            'exp_4_polaron': {
                'name': 'æåŒ–å­è½¬å˜éªŒè¯å®éªŒ',
                'script': 'exp_4_polaron/run_polaron_experiment.py',
                'description': 'éªŒè¯æåŒ–å­è½¬å˜æœºåˆ¶'
            },
            'exp_5_synergy': {
                'name': 'ååŒæ•ˆåº”å®šé‡éªŒè¯å®éªŒ',
                'script': 'exp_5_synergy/run_synergy_experiment.py',
                'description': 'éªŒè¯åº”å˜-æºæ‚ååŒæ•ˆåº”'
            },
            'exp_6_optimal': {
                'name': 'æœ€ä¼˜æ¡ä»¶éªŒè¯å®éªŒ',
                'script': 'exp_6_optimal/run_optimal_experiment.py',
                'description': 'éªŒè¯æœ€ä¼˜æºæ‚æ¡ä»¶'
            }
        }
        
        # åˆ›å»ºç»“æœç›®å½•
        self.results_dir = self.experiments_dir / "comprehensive_results"
        self.results_dir.mkdir(exist_ok=True)
    
    def run_single_experiment(self, exp_id: str) -> Dict:
        """è¿è¡Œå•ä¸ªå®éªŒ"""
        logger.info(f"ğŸš€ å¼€å§‹è¿è¡Œ {exp_id}: {self.experiments[exp_id]['name']}")
        
        exp_config = self.experiments[exp_id]
        script_path = self.experiments_dir / exp_config['script']
        
        if not script_path.exists():
            logger.warning(f"å®éªŒè„šæœ¬ä¸å­˜åœ¨: {script_path}")
            return {
                'experiment_id': exp_id,
                'status': 'skipped',
                'reason': 'script_not_found',
                'results': None
            }
        
        try:
            # è¿è¡Œå®éªŒè„šæœ¬
            start_time = time.time()
            result = subprocess.run(
                [sys.executable, str(script_path)],
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=3600  # 1å°æ—¶è¶…æ—¶
            )
            
            execution_time = time.time() - start_time
            
            if result.returncode == 0:
                logger.info(f"âœ… {exp_id} è¿è¡ŒæˆåŠŸï¼Œç”¨æ—¶: {execution_time:.2f}s")
                
                # è¯»å–å®éªŒç»“æœ
                exp_dir = self.experiments_dir / exp_id
                validation_report_file = exp_dir / "results" / "validation_report.json"
                
                if validation_report_file.exists():
                    with open(validation_report_file, 'r') as f:
                        validation_report = json.load(f)
                    
                    return {
                        'experiment_id': exp_id,
                        'status': 'success',
                        'execution_time': execution_time,
                        'results': validation_report,
                        'stdout': result.stdout,
                        'stderr': result.stderr
                    }
                else:
                    return {
                        'experiment_id': exp_id,
                        'status': 'success_no_results',
                        'execution_time': execution_time,
                        'results': None,
                        'stdout': result.stdout,
                        'stderr': result.stderr
                    }
            else:
                logger.error(f"âŒ {exp_id} è¿è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
                return {
                    'experiment_id': exp_id,
                    'status': 'failed',
                    'execution_time': execution_time,
                    'results': None,
                    'stdout': result.stdout,
                    'stderr': result.stderr,
                    'return_code': result.returncode
                }
                
        except subprocess.TimeoutExpired:
            logger.error(f"â° {exp_id} è¿è¡Œè¶…æ—¶")
            return {
                'experiment_id': exp_id,
                'status': 'timeout',
                'execution_time': 3600,
                'results': None,
                'stdout': '',
                'stderr': 'Timeout after 1 hour'
            }
        except Exception as e:
            logger.error(f"ğŸ’¥ {exp_id} è¿è¡Œå¼‚å¸¸: {e}")
            return {
                'experiment_id': exp_id,
                'status': 'error',
                'execution_time': 0,
                'results': None,
                'stdout': '',
                'stderr': str(e)
            }
    
    def run_all_experiments(self, experiment_list: List[str] = None) -> Dict:
        """è¿è¡Œæ‰€æœ‰å®éªŒ"""
        if experiment_list is None:
            experiment_list = list(self.experiments.keys())
        
        logger.info(f"ğŸ¯ å¼€å§‹è¿è¡Œ {len(experiment_list)} ä¸ªå®éªŒ")
        
        all_results = {}
        start_time = time.time()
        
        for exp_id in experiment_list:
            if exp_id not in self.experiments:
                logger.warning(f"æœªçŸ¥å®éªŒID: {exp_id}")
                continue
            
            exp_result = self.run_single_experiment(exp_id)
            all_results[exp_id] = exp_result
            
            # æ·»åŠ å»¶è¿Ÿé¿å…ç³»ç»Ÿè¿‡è½½
            time.sleep(2)
        
        total_time = time.time() - start_time
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        comprehensive_report = self.generate_comprehensive_report(all_results, total_time)
        
        # ä¿å­˜ç»“æœ
        self.save_comprehensive_results(all_results, comprehensive_report)
        
        return {
            'experiment_results': all_results,
            'comprehensive_report': comprehensive_report,
            'total_execution_time': total_time
        }
    
    def generate_comprehensive_report(self, all_results: Dict, total_time: float) -> Dict:
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        logger.info("ğŸ“Š ç”Ÿæˆç»¼åˆå®éªŒæŠ¥å‘Š...")
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_experiments = len(all_results)
        successful_experiments = sum(1 for r in all_results.values() if r['status'] == 'success')
        failed_experiments = sum(1 for r in all_results.values() if r['status'] == 'failed')
        skipped_experiments = sum(1 for r in all_results.values() if r['status'] == 'skipped')
        
        # éªŒè¯ç»“æœç»Ÿè®¡
        validation_summary = {}
        for exp_id, result in all_results.items():
            if result['status'] == 'success' and result['results']:
                validation_results = result['results'].get('validation_results', {})
                validation_summary[exp_id] = {
                    'overall_valid': validation_results.get('overall_valid', False),
                    'validation_details': validation_results
                }
        
        # è®¡ç®—æ€»ä½“æˆåŠŸç‡
        overall_success_rate = successful_experiments / total_experiments if total_experiments > 0 else 0
        
        # è®¡ç®—éªŒè¯æˆåŠŸç‡
        valid_experiments = sum(1 for v in validation_summary.values() if v['overall_valid'])
        validation_success_rate = valid_experiments / len(validation_summary) if validation_summary else 0
        
        comprehensive_report = {
            'summary': {
                'total_experiments': total_experiments,
                'successful_experiments': successful_experiments,
                'failed_experiments': failed_experiments,
                'skipped_experiments': skipped_experiments,
                'overall_success_rate': overall_success_rate,
                'validation_success_rate': validation_success_rate,
                'total_execution_time': total_time
            },
            'experiment_details': {},
            'validation_summary': validation_summary,
            'recommendations': self._generate_recommendations(all_results, validation_summary)
        }
        
        # æ·»åŠ å®éªŒè¯¦æƒ…
        for exp_id, result in all_results.items():
            exp_config = self.experiments[exp_id]
            comprehensive_report['experiment_details'][exp_id] = {
                'name': exp_config['name'],
                'description': exp_config['description'],
                'status': result['status'],
                'execution_time': result.get('execution_time', 0),
                'overall_valid': result['results'].get('validation_results', {}).get('overall_valid', False) if result['results'] else False
            }
        
        return comprehensive_report
    
    def _generate_recommendations(self, all_results: Dict, validation_summary: Dict) -> List[str]:
        """ç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        # åŸºäºæˆåŠŸç‡
        successful_count = sum(1 for r in all_results.values() if r['status'] == 'success')
        total_count = len(all_results)
        
        if successful_count / total_count < 0.8:
            recommendations.append("å®éªŒæˆåŠŸç‡è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥å®éªŒç¯å¢ƒå’Œè„šæœ¬é…ç½®")
        
        # åŸºäºéªŒè¯ç»“æœ
        valid_count = sum(1 for v in validation_summary.values() if v['overall_valid'])
        if valid_count < len(validation_summary) * 0.8:
            recommendations.append("éªŒè¯æˆåŠŸç‡è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥ç†è®ºé¢„æµ‹å€¼å’Œå®éªŒå‚æ•°")
        
        # åŸºäºå…·ä½“å®éªŒ
        failed_experiments = [exp_id for exp_id, result in all_results.items() if result['status'] == 'failed']
        if failed_experiments:
            recommendations.append(f"ä»¥ä¸‹å®éªŒéœ€è¦é‡ç‚¹å…³æ³¨: {', '.join(failed_experiments)}")
        
        # åŸºäºæ‰§è¡Œæ—¶é—´
        long_running_experiments = [exp_id for exp_id, result in all_results.items() 
                                  if result.get('execution_time', 0) > 300]  # 5åˆ†é’Ÿä»¥ä¸Š
        if long_running_experiments:
            recommendations.append(f"ä»¥ä¸‹å®éªŒæ‰§è¡Œæ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®ä¼˜åŒ–: {', '.join(long_running_experiments)}")
        
        if not recommendations:
            recommendations.append("æ‰€æœ‰å®éªŒè¿è¡Œè‰¯å¥½ï¼Œå»ºè®®ç»§ç»­åç»­åˆ†æ")
        
        return recommendations
    
    def save_comprehensive_results(self, all_results: Dict, comprehensive_report: Dict):
        """ä¿å­˜ç»¼åˆç»“æœ"""
        logger.info("ğŸ’¾ ä¿å­˜ç»¼åˆå®éªŒç»“æœ...")
        
        def convert_numpy_types(obj):
            """è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹"""
            if isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, np.bool_):
                return bool(obj)
            elif isinstance(obj, dict):
                return {key: convert_numpy_types(value) for key, value in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(item) for item in obj]
            else:
                return obj
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        detailed_results_file = self.results_dir / "detailed_results.json"
        with open(detailed_results_file, 'w') as f:
            json.dump(convert_numpy_types(all_results), f, indent=2)
        
        # ä¿å­˜ç»¼åˆæŠ¥å‘Š
        comprehensive_report_file = self.results_dir / "comprehensive_report.json"
        with open(comprehensive_report_file, 'w') as f:
            json.dump(convert_numpy_types(comprehensive_report), f, indent=2)
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        markdown_report = self._generate_markdown_report(comprehensive_report)
        markdown_file = self.results_dir / "comprehensive_report.md"
        with open(markdown_file, 'w', encoding='utf-8') as f:
            f.write(markdown_report)
        
        logger.info(f"ç»“æœå·²ä¿å­˜:")
        logger.info(f"  è¯¦ç»†ç»“æœ: {detailed_results_file}")
        logger.info(f"  ç»¼åˆæŠ¥å‘Š: {comprehensive_report_file}")
        logger.info(f"  MarkdownæŠ¥å‘Š: {markdown_file}")
    
    def _generate_markdown_report(self, comprehensive_report: Dict) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„ç»¼åˆæŠ¥å‘Š"""
        summary = comprehensive_report['summary']
        experiment_details = comprehensive_report['experiment_details']
        validation_summary = comprehensive_report['validation_summary']
        recommendations = comprehensive_report['recommendations']
        
        report = f"""# ç»¼åˆå®éªŒéªŒè¯æŠ¥å‘Š

## æ‰§è¡Œæ‘˜è¦

- **æ€»å®éªŒæ•°**: {summary['total_experiments']}
- **æˆåŠŸå®éªŒæ•°**: {summary['successful_experiments']}
- **å¤±è´¥å®éªŒæ•°**: {summary['failed_experiments']}
- **è·³è¿‡å®éªŒæ•°**: {summary['skipped_experiments']}
- **æ€»ä½“æˆåŠŸç‡**: {summary['overall_success_rate']:.1%}
- **éªŒè¯æˆåŠŸç‡**: {summary['validation_success_rate']:.1%}
- **æ€»æ‰§è¡Œæ—¶é—´**: {summary['total_execution_time']:.2f} ç§’

## å®éªŒè¯¦æƒ…

| å®éªŒID | å®éªŒåç§° | çŠ¶æ€ | æ‰§è¡Œæ—¶é—´(s) | éªŒè¯ç»“æœ |
|--------|----------|------|-------------|----------|
"""
        
        for exp_id, details in experiment_details.items():
            status_emoji = {
                'success': 'âœ…',
                'failed': 'âŒ',
                'skipped': 'â­ï¸',
                'timeout': 'â°',
                'error': 'ğŸ’¥'
            }.get(details['status'], 'â“')
            
            validation_emoji = 'âœ“' if details['overall_valid'] else 'âœ—'
            
            report += f"| {exp_id} | {details['name']} | {status_emoji} {details['status']} | {details['execution_time']:.2f} | {validation_emoji} |\n"
        
        report += f"""
## éªŒè¯ç»“æœè¯¦æƒ…

"""
        
        for exp_id, validation in validation_summary.items():
            exp_name = experiment_details[exp_id]['name']
            overall_valid = validation['overall_valid']
            validation_details = validation['validation_details']
            
            report += f"### {exp_name} ({exp_id})\n\n"
            report += f"**æ€»ä½“éªŒè¯**: {'âœ… é€šè¿‡' if overall_valid else 'âŒ æœªé€šè¿‡'}\n\n"
            
            if validation_details:
                report += "**è¯¦ç»†éªŒè¯ç»“æœ**:\n"
                for key, value in validation_details.items():
                    if isinstance(value, bool):
                        emoji = 'âœ“' if value else 'âœ—'
                        report += f"- {key}: {emoji}\n"
                    else:
                        report += f"- {key}: {value}\n"
            
            report += "\n"
        
        report += f"""
## å»ºè®®

"""
        
        for i, recommendation in enumerate(recommendations, 1):
            report += f"{i}. {recommendation}\n"
        
        report += f"""
## ç»“è®º

åŸºäº {summary['total_experiments']} ä¸ªå®éªŒçš„ç»¼åˆéªŒè¯ç»“æœï¼š

- **å®éªŒæ‰§è¡Œ**: {summary['successful_experiments']}/{summary['total_experiments']} ä¸ªå®éªŒæˆåŠŸæ‰§è¡Œ
- **ç†è®ºéªŒè¯**: {len([v for v in validation_summary.values() if v['overall_valid']])}/{len(validation_summary)} ä¸ªå®éªŒé€šè¿‡ç†è®ºéªŒè¯
- **æ•´ä½“è¯„ä¼°**: {'å®éªŒéªŒè¯æˆåŠŸ' if summary['validation_success_rate'] > 0.8 else 'éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–'}

"""
        
        return report
    
    def run_experiments_1_and_2(self):
        """è¿è¡Œå®éªŒ1å’Œ2ï¼ˆå·²å®ç°çš„å®éªŒï¼‰"""
        logger.info("ğŸ¯ è¿è¡Œå®éªŒ1å’Œ2ï¼ˆå·²å®ç°çš„å®éªŒï¼‰")
        
        experiment_list = ['exp_1_structure', 'exp_2_doping']
        return self.run_all_experiments(experiment_list)
    
    def run_all_6_experiments(self):
        """è¿è¡Œæ‰€æœ‰6ä¸ªå®éªŒ"""
        logger.info("ğŸ¯ è¿è¡Œæ‰€æœ‰6ä¸ªå®éªŒ")
        
        experiment_list = ['exp_1_structure', 'exp_2_doping', 'exp_3_electronic', 
                          'exp_4_polaron', 'exp_5_synergy', 'exp_6_optimal']
        return self.run_all_experiments(experiment_list)

def main():
    """ä¸»å‡½æ•°"""
    runner = ComprehensiveExperimentRunner()
    
    # è¿è¡Œæ‰€æœ‰6ä¸ªå®éªŒ
    results = runner.run_all_6_experiments()
    
    # è¾“å‡ºæ€»ç»“
    comprehensive_report = results['comprehensive_report']
    summary = comprehensive_report['summary']
    
    logger.info("ğŸ‰ ç»¼åˆå®éªŒå®Œæˆ!")
    logger.info(f"  æ€»å®éªŒæ•°: {summary['total_experiments']}")
    logger.info(f"  æˆåŠŸå®éªŒæ•°: {summary['successful_experiments']}")
    logger.info(f"  æ€»ä½“æˆåŠŸç‡: {summary['overall_success_rate']:.1%}")
    logger.info(f"  éªŒè¯æˆåŠŸç‡: {summary['validation_success_rate']:.1%}")
    logger.info(f"  æ€»æ‰§è¡Œæ—¶é—´: {summary['total_execution_time']:.2f} ç§’")
    
    return results

if __name__ == "__main__":
    main()
